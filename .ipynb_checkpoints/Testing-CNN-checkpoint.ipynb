{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae0a1e9-eddc-4625-ad93-0a7aba4b3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada4a3d5-91ea-4efe-abf2-a67fa06b6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ale_py in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: numpy>1.20 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from ale_py) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5be514-3f69-491e-b172-2ba7dbd662dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from gymnasium[atari]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from gymnasium[atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from gymnasium[atari]) (4.13.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in c:\\users\\mmooreii\\appdata\\local\\anaconda3\\lib\\site-packages (from gymnasium[atari]) (0.10.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"gymnasium[atari]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e4f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import ale_py\n",
    "from tensorflow.keras import layers, models\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6091137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    # Convert to grayscale and resize to 120x160\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    resized_frame = cv2.resize(gray_frame, (160, 120))\n",
    "    normalized_frame = resized_frame / 255.0  # Normalize to [0, 1]\n",
    "    return normalized_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9114e015-c9eb-451b-bdf6-bc8a8d714e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(action_size):\n",
    "    \"\"\"CNN architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=(210, 160, 1)))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(action_size, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.00025))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdae6fe6-eb82-45e8-8595-4f69114e5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System for progressively saving weights as the CNN trains\n",
    "def create_memory(capacity=100000):\n",
    "    \"\"\"Create a memory buffer for experience replay\"\"\"\n",
    "    return deque(maxlen=capacity)\n",
    "\n",
    "def add_to_memory(memory, state, action, reward, next_state, done):\n",
    "    \"\"\"Add experience to memory\"\"\"\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "def sample_from_memory(memory, batch_size):\n",
    "    \"\"\"Sample random batch from memory\"\"\"\n",
    "    return random.sample(memory, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc3db75-c6d8-4986-80aa-88d8ee4ed17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(model, state, epsilon, action_size):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return np.random.randint(action_size)  # Random action (explore)\n",
    "    q_values = model.predict(np.expand_dims(state, axis=0), verbose=0)  # Predict Q-values\n",
    "    return np.argmax(q_values[0])  # Action with highest Q-value (exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07bd1d54-161a-4e72-a6be-5e120f7da915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture for action prediction\n",
    "def build_cnn(action_size, input_shape=(120, 160, 1)):\n",
    "    \"\"\"\n",
    "    Build a Convolutional Neural Network (CNN) for action prediction in an RL environment.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(64, (4, 4), strides=2, activation='relu'))\n",
    "    \n",
    "    # Third convolutional layer\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=1, activation='relu'))\n",
    "    \n",
    "    # Flatten the output for the fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Fully connected layer\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    \n",
    "    # Output layer with 'action_size' neurons (one for each possible action)\n",
    "    model.add(layers.Dense(action_size, activation='softmax'))  # Softmax for action probability\n",
    "\n",
    "    # Compile the model with a categorical crossentropy loss (because it's a classification task)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eb77a63-ffbb-4202-a802-ff9c682b8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(episodes=10000, \n",
    "              max_steps=50000, \n",
    "              batch_size=32, \n",
    "              epsilon_start=1.0, \n",
    "              epsilon_end=0.1, \n",
    "              epsilon_decay=0.995,\n",
    "              memory_capacity=100000,\n",
    "              save_freq=100):\n",
    "    \"\"\"Train a CNN model for action prediction on the Frogger environment\"\"\"\n",
    "    # Create environment\n",
    "    env = gym.make('ALE/Frogger-v5')\n",
    "    action_size = env.action_space.n\n",
    "    \n",
    "    # Create CNN model\n",
    "    model = build_cnn(action_size)\n",
    "    \n",
    "    # Model saving directory\n",
    "    save_dir = \"frogger_model\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Initialize memory\n",
    "    memory = []\n",
    "    \n",
    "    # Training loop\n",
    "    epsilon = epsilon_start\n",
    "    for episode in range(1, episodes + 1):\n",
    "        start_time = time.time()\n",
    "\n",
    "        frame, info = env.reset()\n",
    "        state = preprocess_frame(frame)\n",
    "        state = np.expand_dims(state, axis=-1)\n",
    "\n",
    "        episode_reward = 0\n",
    "        steps_taken = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = epsilon_greedy_action(model, state, epsilon, action_size)\n",
    "            next_frame, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # Reward shaping for completion speed\n",
    "            time_penalty = 0.01\n",
    "            speed_bonus = 10 if done and reward > 0 else 0\n",
    "            reward = reward - (step * time_penalty) + speed_bonus\n",
    "            reward = np.clip(reward, -10, 10)\n",
    "\n",
    "            next_state = preprocess_frame(next_frame)\n",
    "            next_state = np.expand_dims(next_state, axis=-1)\n",
    "\n",
    "            memory.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            steps_taken += 1\n",
    "            \n",
    "            # If memory has enough samples, train the model (optional)\n",
    "            if len(memory) > batch_size:\n",
    "                # Sample a minibatch from memory\n",
    "                minibatch = random.sample(memory, batch_size)\n",
    "                \n",
    "                # Prepare training data from minibatch\n",
    "                states = np.array([experience[0] for experience in minibatch])\n",
    "                actions = np.array([experience[1] for experience in minibatch])\n",
    "                rewards = np.array([experience[2] for experience in minibatch])\n",
    "                next_states = np.array([experience[3] for experience in minibatch])\n",
    "                dones = np.array([experience[4] for experience in minibatch])\n",
    "                \n",
    "                # One-hot encode the actions for categorical crossentropy\n",
    "                actions_one_hot = tf.keras.utils.to_categorical(actions, num_classes=action_size)\n",
    "                \n",
    "                # Train the model using the states and actions\n",
    "                model.fit(states, actions_one_hot, epochs=1, verbose=0)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Decay epsilon for exploration-exploitation balance\n",
    "        if epsilon > epsilon_end:\n",
    "            epsilon *= epsilon_decay\n",
    "        \n",
    "        # Print episode stats\n",
    "        print(f\"Episode: {episode}, Reward: {episode_reward}, Epsilon: {epsilon:.4f}, Steps: {step+1}\")\n",
    "        \n",
    "        # Save the model periodically\n",
    "        if episode % save_freq == 0:\n",
    "            model.save(f\"{save_dir}/frogger_cnn_episode_{episode}.h5\")\n",
    "            print(f\"Model saved at episode {episode}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    model.save(f\"{save_dir}/frogger_cnn_final.h5\")\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    env.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d68dd17-e235-4ef6-8d2b-8f29c4b02f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Reward: 9.0, Epsilon: 0.9950, Steps: 313\n",
      "Episode: 2, Reward: 9.0, Epsilon: 0.9900, Steps: 295\n",
      "Episode: 3, Reward: 7.0, Epsilon: 0.9851, Steps: 288\n",
      "Episode: 4, Reward: 13.0, Epsilon: 0.9801, Steps: 261\n",
      "Episode: 5, Reward: 12.0, Epsilon: 0.9752, Steps: 248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m train_cnn(episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 69\u001b[0m, in \u001b[0;36mtrain_cnn\u001b[1;34m(episodes, max_steps, batch_size, epsilon_start, epsilon_end, epsilon_decay, memory_capacity, save_freq)\u001b[0m\n\u001b[0;32m     66\u001b[0m     actions_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(actions, num_classes\u001b[38;5;241m=\u001b[39maction_size)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Train the model using the states and actions\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(states, actions_one_hot, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:332\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    325\u001b[0m     (\n\u001b[0;32m    326\u001b[0m         val_x,\n\u001b[0;32m    327\u001b[0m         val_y,\n\u001b[0;32m    328\u001b[0m         val_sample_weight,\n\u001b[0;32m    329\u001b[0m     ) \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Create an iterator that yields batches for one epoch.\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    333\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    334\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    336\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    337\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    338\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    339\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m    340\u001b[0m     distribute_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    341\u001b[0m     steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution,\n\u001b[0;32m    342\u001b[0m )\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_symbolic_build(iterator\u001b[38;5;241m=\u001b[39mepoch_iterator)\n\u001b[0;32m    345\u001b[0m epoch_iterator\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:720\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[1;32m--> 720\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_adapter\u001b[38;5;241m.\u001b[39mget_tf_dataset()\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[0;32m    722\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[0;32m    723\u001b[0m         dataset\n\u001b[0;32m    724\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:140\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# performance.\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(permutation)\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        A Dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1268\u001b[0m, in \u001b[0;36mDatasetV2.prefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprefetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer_size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \n\u001b[0;32m   1243\u001b[0m \u001b[38;5;124;03m  Most dataset input pipelines should end with a call to `prefetch`. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m prefetch_op\u001b[38;5;241m.\u001b[39m_prefetch(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m       \u001b[38;5;28mself\u001b[39m, buffer_size, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:28\u001b[0m, in \u001b[0;36m_prefetch\u001b[1;34m(input_dataset, buffer_size, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m input_dataset\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _PrefetchDataset(input_dataset, buffer_size, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:46\u001b[0m, in \u001b[0;36m_PrefetchDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# We colocate the prefetch dataset with its input as this collocation only\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# happens automatically in graph mode.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m---> 46\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mprefetch_dataset(\n\u001b[0;32m     47\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m     48\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[0;32m     49\u001b[0m       slack_period\u001b[38;5;241m=\u001b[39mslack_period,\n\u001b[0;32m     50\u001b[0m       legacy_autotune\u001b[38;5;241m=\u001b[39m(buffer_size \u001b[38;5;241m==\u001b[39m dataset_ops\u001b[38;5;241m.\u001b[39mAUTOTUNE),\n\u001b[0;32m     51\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6015\u001b[0m, in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   6013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6014\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6015\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   6016\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrefetchDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, input_dataset, buffer_size,\n\u001b[0;32m   6017\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_types\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_types, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_shapes,\n\u001b[0;32m   6018\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslack_period\u001b[39m\u001b[38;5;124m\"\u001b[39m, slack_period, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_autotune\u001b[39m\u001b[38;5;124m\"\u001b[39m, legacy_autotune,\n\u001b[0;32m   6019\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer_size_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, buffer_size_min, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata)\n\u001b[0;32m   6020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6021\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_cnn(episodes=1000, max_steps=50000, batch_size=32)\n",
    "#Pray it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ddd07-55d3-4644-be76-073cac91ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
